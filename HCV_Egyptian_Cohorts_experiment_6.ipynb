{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Machine Learning to a Hepatitis C Egyptian Cohort Dataset for Predicting the Disease Stage - Experiment 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-class prediction\n",
    "* [F1 vs F4](#first-bullet)&nbsp;(<font color=\"red\">F2=F3=0, F1=1 and F4=4</font>)\n",
    "* [F1 vs. F3+F4](#second-bullet) &nbsp;(<font color=\"red\">F2=0, F1=1 and F3+F4=4</font>)\n",
    "* [F1 vs. F2+F3+F4](#third-bullet) &nbsp;(<font color=\"red\">F1=1 and F2+F3+F4=4</font>)\n",
    "* [F1 vs. F2+F3](#fourth-bullet) &nbsp;(<font color=\"red\">F4=0, F1=1 and F2+F3=2</font>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CommonUtilsHCV import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_connection(conn=\"Connected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset downloaded from https://archive.ics.uci.edu/ml/machine-learning-databases/00503/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(r\"HCV_Egy_data_for_loading.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of observations in data:\", \" \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"BHS\"].value_counts(sort=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 vs. F4  <a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp1 = data.loc[data[\"BHS\"] != 3]\n",
    "data_tmp = data_tmp1.loc[data_tmp1[\"BHS\"] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp[\"BHS\"].value_counts(sort=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "data_lists = []\n",
    "X,y = standard_scaler(dataframe=data_tmp)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=20)\n",
    "\n",
    "data_lists = [X_train, y_train, X_test, y_test]\n",
    "label_names = y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_result = get_all_the_best_values(data_lists=data_lists, experiment_name=\"Experiment_61\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "#create a dictionary of the models\n",
    "estimators = [\n",
    "#     ('lr', models_result[0]['best_param']), \n",
    "#               ('nb', models_result[1]['best_param']),\n",
    "              ('dt', models_result[2]['best_param']),\n",
    "              ('rf', models_result[3]['best_param']),\n",
    "              ('xgb', models_result[4]['best_param']),\n",
    "              ('knn', models_result[5]['best_param']), \n",
    "#              ('svm', models_result[6]['best_param']) #,\n",
    "#               ('nn', models_result[7]['best_param'])\n",
    "             ]\n",
    "#create our voting classifier, inputting our models\n",
    "ensemble = VotingClassifier(estimators, voting=\"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ensemble.fit(data_lists[0], data_lists[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ensemble.predict(data_lists[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_metrics_2d(y_pred=pred, y_test=data_lists[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 vs. F3+F4   <a class=\"anchor\" id=\"second-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp = data.loc[data[\"BHS\"] != 2]\n",
    "data_tmp[\"BHS\"] = np.where(data_tmp[\"BHS\"]<=2 , 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp[\"BHS\"].value_counts(sort=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority = data_tmp[data_tmp[\"BHS\"]==4]\n",
    "df_minority = data_tmp[data_tmp[\"BHS\"]==1]\n",
    "\n",
    "#Downsample majority class\n",
    "df_majority_downsampled = resample(df_minority,\n",
    "                                  replace=True,\n",
    "                                  n_samples=717,\n",
    "                                  random_state=123)\n",
    "\n",
    "# concat the minority and majority downsampled dataframe\n",
    "df_downsampled = pd.concat([df_majority, df_majority_downsampled])\n",
    "\n",
    "# Display new class counts\n",
    "df_downsampled.BHS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp = df_downsampled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp[\"BHS\"].value_counts(sort=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "data_lists = []\n",
    "X,y = standard_scaler(dataframe=data_tmp)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=20)\n",
    "\n",
    "data_lists = [X_train, y_train, X_test, y_test]\n",
    "label_names = y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_result = get_all_the_best_values(data_lists=data_lists, experiment_name=\"Experiment_62\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "#create a dictionary of the models\n",
    "estimators = [\n",
    "#     ('lr', models_result[0]['best_param']), \n",
    "#               ('nb', models_result[1]['best_param']),\n",
    "              ('dt', models_result[2]['best_param']),\n",
    "              ('rf', models_result[3]['best_param']),\n",
    "              ('xgb', models_result[4]['best_param']),\n",
    "              ('knn', models_result[5]['best_param']), \n",
    "              ('svm', models_result[6]['best_param']) #,\n",
    "#               ('nn', models_result[7]['best_param'])\n",
    "             ]\n",
    "#create our voting classifier, inputting our models\n",
    "ensemble = VotingClassifier(estimators, voting=\"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ensemble.fit(data_lists[0], data_lists[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ensemble.predict(data_lists[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_metrics_2d(y_pred=pred, y_test=data_lists[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 vs. F2+F3+F4  <a class=\"anchor\" id=\"third-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp = data.copy()\n",
    "data_tmp[\"BHS\"] = np.where(data_tmp[\"BHS\"]==1 , 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp[\"BHS\"].value_counts(sort=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority = data_tmp[data_tmp[\"BHS\"]==4]\n",
    "df_minority = data_tmp[data_tmp[\"BHS\"]==1]\n",
    "\n",
    "#Downsample majority class\n",
    "df_majority_downsampled = resample(df_minority,\n",
    "                                  replace=True,\n",
    "                                  n_samples=1049,\n",
    "                                  random_state=123)\n",
    "\n",
    "# concat the minority and majority downsampled dataframe\n",
    "df_downsampled = pd.concat([df_majority, df_majority_downsampled])\n",
    "\n",
    "# Display new class counts\n",
    "df_downsampled.BHS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp = df_downsampled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp[\"BHS\"].value_counts(sort=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "data_lists = []\n",
    "X,y = standard_scaler(dataframe=data_tmp)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=20)\n",
    "\n",
    "data_lists = [X_train, y_train, X_test, y_test]\n",
    "label_names = y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_result = get_all_the_best_values(data_lists=data_lists, experiment_name=\"Experiment_6c\")\n",
    "# get_the_best_values_KNN(data_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
    "#                       metric_params=None, n_jobs=None, n_neighbors=1, p=1,\n",
    "#                       weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "#                colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "#                learning_rate=0.075, max_delta_step=0, max_depth=9,\n",
    "#                min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
    "#                nthread=1, number_of_estimators=1, objective='binary:logistic',\n",
    "#                random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "#                seed=None, silent=None, subsample=1, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#                         max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
    "#                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#                         min_samples_leaf=1, min_samples_split=2,\n",
    "#                         min_weight_fraction_leaf=0.0, n_estimators=130,\n",
    "#                         n_jobs=None, oob_score=True, random_state=None,\n",
    "#                         verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "#create a dictionary of the models\n",
    "estimators = [\n",
    "#               ('lr', models_result[0]['best_param']), \n",
    "#               ('nb', models_result[1]['best_param']),\n",
    "              ('dt', models_result[2]['best_param']),\n",
    "              ('rf', models_result[3]['best_param']),\n",
    "              ('xgb', models_result[4]['best_param']),\n",
    "              ('knn', models_result[5]['best_param']), \n",
    "              ('svm', models_result[6]['best_param']) #,\n",
    "#               ('nn', models_result[7]['best_param'])\n",
    "             ]\n",
    "#create our voting classifier, inputting our models\n",
    "ensemble = VotingClassifier(estimators, voting=\"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ensemble.fit(data_lists[0], data_lists[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ensemble.predict(data_lists[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_metrics_2d(y_pred=pred, y_test=data_lists[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\"Age\",\"AST1\", \"ALT1\", \"Plat\", \"BMI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "train, test, labels_train, labels_test = sklearn.model_selection.train_test_split(data_tmp[feature_names], \n",
    "                                                                                  data_tmp[\"BHS\"], \n",
    "                                                                                  train_size=0.70, \n",
    "                                                                                  test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#                         max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
    "#                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#                         min_samples_leaf=1, min_samples_split=2,\n",
    "#                         min_weight_fraction_leaf=0.0, n_estimators=130,\n",
    "#                         n_jobs=None, oob_score=True, random_state=None,\n",
    "#                         verbose=0, warm_start=False)\n",
    "# # rf = RandomForestClassifier()\n",
    "# rf.fit(train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "#               colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "#               learning_rate=0.075, max_delta_step=0, max_depth=9,\n",
    "#               min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
    "#               nthread=1, number_of_estimators=1, objective='binary:logistic',\n",
    "#               random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "#               seed=None, silent=None, subsample=1, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
    "                      metric_params=None, n_jobs=None, n_neighbors=1, p=1,\n",
    "                      weights='uniform')\n",
    "knn.fit(train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prob(data1):\n",
    "#     return rf.predict_proba(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "#     train.astype(int).values,\n",
    "    train.values,\n",
    "    training_labels = labels_train.astype(int).values,\n",
    "    feature_names=feature_names, \n",
    "    class_names=[1, 4],\n",
    "    mode=\"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rows = [1, 300, 20, 3] \n",
    "# rows = [20, 1, 3, 300, 109, 25, 69] \n",
    "# rows = [575, 36, 52, 227, 29, 122, 38, 1, 21, 4]\n",
    "# rows = np.arange(600, 620, 1).tolist()\n",
    "for row in rows:\n",
    "   print(row)\n",
    "#    exp_all = explainer.explain_instance(test.iloc[row], predict_fn_xgb, num_features=5)\n",
    "   exp_all = explainer.explain_instance(test.iloc[row], knn.predict_proba, num_features=5)\n",
    "   exp_all.show_in_notebook(show_table=True)\n",
    "   print(exp_all.as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the XGB Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first run the previous experiment to get the test and train setsÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "# store the best xgb model in an object\n",
    "X_trn = data_lists[0]\n",
    "y_trn = data_lists[1]\n",
    "X_tst = data_lists[2]\n",
    "y_tst = data_lists[3]\n",
    "param_grid = {'max_depth' : list(range(2,4,1)), \n",
    "              'number_of_estimators' : list(range(1,3,1)), \n",
    "              'learning_rate' : [0.005] #, \n",
    "#                'nthread' : list(range(1,,1))\n",
    "             }\n",
    "xgb = XGBClassifier()\n",
    "clf = GridSearchCV(estimator=xgb, param_grid=param_grid)\n",
    "model_xgb = clf.fit(X_trn, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtc = DecisionTreeClassifier()\n",
    "# dtc.fit(X_trn, y_trn)\n",
    "# perm = PermutationImportance(dtc, random_state=1).fit(X_trn, y_trn)\n",
    "# rfc = RandomForestClassifier()\n",
    "# rfc.fit(X_trn, y_trn)\n",
    "# perm = PermutationImportance(rfc, random_state=1).fit(X_trn, y_trn)\n",
    "xgb = XGBClassifier()\n",
    "model = xgb.fit(X_trn, y_trn)\n",
    "perm = PermutationImportance(xgb, random_state=1).fit(X_trn, y_trn)\n",
    "# knn = KNeighborsClassifier()\n",
    "# knn.fit(X_trn, y_trn)\n",
    "# perm = PermutationImportance(knn, random_state=1).fit(X_trn, y_trn)\n",
    "# svm = SVC()\n",
    "# svm.fit(X_trn, y_trn)\n",
    "# perm = PermutationImportance(svm, random_state=1).fit(X_trn, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp_df(X_trn.columns, perm.feature_importances_)\n",
    "# \"Age\",\"AST1\", \"ALT1\", \"Plat\", \"BMI\"\n",
    "perm.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try other means of feature attributions - SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# conda install -c conda-forge shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
